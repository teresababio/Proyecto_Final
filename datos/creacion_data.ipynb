{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5651a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import Augmentor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a41225",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3f2af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/teresababio/FinalProject/Traffic_sign_classification/datos'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[]\n",
    "labels = []\n",
    "classes = 43\n",
    "cur_path = os.getcwd()\n",
    "cur_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4cd2984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(cur_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29b807d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [2, 3]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(([[1,2],[2,3]])).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64d15a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al leer output 0\n",
      "Error al leer output 3\n",
      "Error al leer output 4\n",
      "Error al leer output 5\n",
      "Error al leer output 6\n",
      "Error al leer output 7\n",
      "Error al leer output 8\n",
      "Error al leer output 9\n",
      "Error al leer output 11\n",
      "Error al leer output 14\n",
      "Error al leer output 15\n",
      "Error al leer output 16\n",
      "Error al leer output 17\n",
      "Error al leer output 18\n",
      "Error al leer output 19\n",
      "Error al leer output 20\n",
      "Error al leer output 21\n",
      "Error al leer output 22\n",
      "Error al leer output 23\n",
      "Error al leer output 24\n",
      "Error al leer output 25\n",
      "Error al leer output 26\n",
      "Error al leer output 27\n",
      "Error al leer output 28\n",
      "Error al leer output 29\n",
      "Error al leer output 30\n",
      "Error al leer output 31\n",
      "Error al leer output 32\n",
      "Error al leer output 33\n",
      "Error al leer output 34\n",
      "Error al leer output 35\n",
      "Error al leer output 36\n",
      "Error al leer output 37\n",
      "Error al leer output 39\n",
      "Error al leer output 40\n",
      "Error al leer output 41\n",
      "Error al leer output 42\n"
     ]
    }
   ],
   "source": [
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,'Train',str(i))\n",
    "    images = os.listdir(path)\n",
    "    for img in images:\n",
    "        img2=img\n",
    "        try:\n",
    "            img_path = os.path.join(path, img)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (50,50), interpolation = cv2.INTER_CUBIC)/255\n",
    "            data.append(img)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(f\"Error al leer {img2} {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b419cefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da32e1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb9bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(columns= [\"label\", \"image\"])\n",
    "train[\"label\"] = labels\n",
    "train[\"image\"] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34339d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.44313725490196076, 0.4, 0.360784313725490...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.6470588235294118, 0.3176470588235294, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.6745098039215687, 0.1450980392156863, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.7019607843137254, 0.6352941176470588, 0.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              image\n",
       "0      0  [[[0.44313725490196076, 0.4, 0.360784313725490...\n",
       "1      0  [[[0.6470588235294118, 0.3176470588235294, 0.3...\n",
       "2      0  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...\n",
       "3      0  [[[0.6745098039215687, 0.1450980392156863, 0.1...\n",
       "4      0  [[[0.7019607843137254, 0.6352941176470588, 0.6..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f472213a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1a7218e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     2250\n",
       "1     2220\n",
       "13    2160\n",
       "12    2100\n",
       "38    2070\n",
       "10    2010\n",
       "4     1980\n",
       "5     1860\n",
       "25    1500\n",
       "9     1470\n",
       "7     1440\n",
       "3     1410\n",
       "8     1410\n",
       "11    1320\n",
       "35    1200\n",
       "18    1200\n",
       "17    1110\n",
       "31     780\n",
       "14     780\n",
       "33     689\n",
       "15     630\n",
       "26     600\n",
       "28     540\n",
       "23     510\n",
       "30     450\n",
       "16     420\n",
       "34     420\n",
       "6      420\n",
       "36     390\n",
       "22     390\n",
       "40     360\n",
       "20     360\n",
       "21     330\n",
       "39     300\n",
       "29     270\n",
       "24     270\n",
       "41     240\n",
       "42     240\n",
       "32     240\n",
       "27     240\n",
       "37     210\n",
       "19     210\n",
       "0      210\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ea625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a09b9bb7",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label,value in zip(train[\"label\"].value_counts().index, train[\"label\"].value_counts().values) :\n",
    "    if 2000>value:\n",
    "        print(label, value)\n",
    "        path = os.path.join(cur_path,'Train',str(label), 'output')\n",
    "        if not os.path.exists(path):\n",
    "            print(\"Creacion de carpeta output\")\n",
    "            p = Augmentor.Pipeline(os.path.join(cur_path,'Train',str(label)))\n",
    "            p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "            p.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)\n",
    "            p.skew(probability=0.6)\n",
    "            p.sample(2000-value)  \n",
    "        \n",
    " \n",
    "        images = os.listdir(path)\n",
    "        for img in images:\n",
    "            img2=img\n",
    "            try:\n",
    "                img_path = os.path.join(path, img)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (50,50), interpolation = cv2.INTER_CUBIC)/255\n",
    "                data.append(img)\n",
    "                labels.append(label)\n",
    "            except:\n",
    "                print(f\"Error al leer {img2}\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(columns= [\"label\", \"image\"])\n",
    "train[\"label\"] = labels\n",
    "train[\"image\"] = data \n",
    "train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88567732",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0deae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv( 'Test.csv')\n",
    "\n",
    "labels = test[\"ClassId\"].values\n",
    "\n",
    "\n",
    "\n",
    "data =[]\n",
    "path = os.path.join(cur_path,'Test')\n",
    "images = os.listdir(path)\n",
    "\n",
    "for img in images:\n",
    "        img2= img\n",
    "        try:\n",
    "            img_path = os.path.join(path, img)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (50,50), interpolation = cv2.INTER_CUBIC)/255\n",
    "            data.append(img)\n",
    "        except:\n",
    "            print(f\"Error al leer {img2}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e027bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(columns= [\"label\", \"image\"])\n",
    "test[\"label\"] = labels\n",
    "test[\"image\"] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2045a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf36ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv(\"data_test.csv\", index = False)\n",
    "#train.to_csv(\"data_train.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163a030",
   "metadata": {},
   "source": [
    "# Modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11fb7ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 13:21:46.108686: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 13:21:46.412145: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/teresababio/miniconda3/envs/core/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-12-22 13:21:46.412174: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-22 13:21:49.672116: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/teresababio/miniconda3/envs/core/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-12-22 13:21:49.672307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/teresababio/miniconda3/envs/core/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-12-22 13:21:49.672323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94025f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44426c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 13:21:52.459063: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/teresababio/miniconda3/envs/core/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-12-22 13:21:52.459188: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-22 13:21:52.459246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-FNGN17J8): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "#Avoid OOM errors by setting PGU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "313af7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 13:21:52.916633: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 50, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 50, 50, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 50, 50, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 25, 25, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 25, 25, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(50,50,3))\n",
    "vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff330aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1, 1, 512)        2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 43)                22059     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,311,147\n",
      "Trainable params: 20,310,123\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model = tf.keras.Sequential([VGG19(weights='imagenet', include_top=False, input_shape=(50,50,3)),\n",
    "                                 keras.layers.BatchNormalization(),\n",
    "                                 keras.layers.Flatten(),\n",
    "                                 keras.layers.Dense(512, activation='sigmoid'),\n",
    "                                 keras.layers.Dense(43, activation='softmax')\n",
    "                                ])\n",
    "vgg_model.layers[0].trainable=True\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f46703d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afe4c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "Y_enc = ohe.fit_transform(np.array(train[\"label\"]).reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75907c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(train[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a900a68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e27df79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 43)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552da67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg_model.fit(X, Y_enc,\n",
    "                        epochs=10,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8d22834",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a963f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0587f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the labels into one hot encoding\n",
    "y_train = to_categorical(labels, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a445cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.fit(data, y_train,\n",
    "                        epochs=10,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c52954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97554c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
